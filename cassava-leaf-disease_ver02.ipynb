{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import albumentations.pytorch as Apy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"drive/MyDrive/Colab Notebooks/train.csv\")\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"drive/MyDrive/Colab Notebooks/training_images\")\n",
    "for i in list(set(train_csv[\"label\"])):\n",
    "    os.mkdir(\"drive/MyDrive/Colab Notebooks/training_images/{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 라벨링을 위한 폴더별로 이미지 넣기\n",
    "for file in tqdm(all_training_files):\n",
    "    # 이미지별 라벨달기\n",
    "    label = int(train_csv[train_csv[\"image_id\"] == file][\"label\"])\n",
    "    dirname = \"drive/MyDrive/Colab Notebooks/train_images/\" + file\n",
    "    outname = \"drive/MyDrive/Colab Notebooks/training_images/{}/{}\".format(label, file)\n",
    "    shutil.copyfile(dirname, outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 및 downloader을 이용한 데이터 셋 만들기\n",
    "data_dir = \"drive/MyDrive/Colab Notebooks/training_images/\"\n",
    "batch_size = 8\n",
    "def get_data_loaders(data_dir, batch_size):\n",
    "    transform = transforms.Compose([transforms.Resize((220, 220)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomVerticalFlip(),\n",
    "                                transforms.RandomRotation(20),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "    all_data = datasets.ImageFolder(data_dir, transform=transform)  \n",
    "    train_data_len = int(len(all_data)*0.75)\n",
    "    valid_data_len = int(len(all_data) - train_data_len)\n",
    "    train_data, val_data = random_split(all_data, [train_data_len, valid_data_len])\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    return ((train_loader, val_loader), all_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_loaders(data_dir, batch_size)\n",
    "(train_loader, val_loader), classes = get_data_loaders(data_dir, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy() # convert images to numpy for display\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(5, 12/2, idx+1, xticks=[], yticks=[])\n",
    "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#현재 토치사이즈 보기\n",
    "imgs = 0\n",
    "for n, (img, labels) in enumerate(train_loader):\n",
    "    print(n, img.shape, labels.shape)\n",
    "    imgs = img\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네트웨크 만들기\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class my_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,64,5)\n",
    "        self.conv2 = nn.Conv2d(64,30,5) \n",
    "        self.fc1 = nn.Linear(30*5*5, 5)\n",
    "        self.fc2 = nn.Linear(5, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x), inplace=True)\n",
    "        x = F.max_pool2d(x,(2,2))\n",
    "        x = F.relu(self.conv2(x), inplace=True)\n",
    "        x = F.max_pool2d(x,(2,2))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        x = F.relu(self.fc2(x), inplace=True)\n",
    "        return x  \n",
    "\n",
    "my_net = my_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실함수 정의\n",
    "optim = torch.optim.SGD(my_net.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련하기\n",
    "epoch_num = 3\n",
    "for epoch in range(epoch_num):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        out = my_net(inputs)\n",
    "        loss = loss_function(out, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    if i % 64 == 0:\n",
    "        print(\"%d => loss : %.3f\" %(i, loss))\n",
    "\n",
    "print(\"train over\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측하기\n",
    "total = 0\n",
    "correct = 0\n",
    "for data in val_loader:\n",
    "    images, labels = data\n",
    "    outputs = my_net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the test images: %f'%(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU 연결\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
